# -*- coding: utf-8 -*-
"""Llama-Law-Finetuning-Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NHoUHPXumVBf2Lef4NiDSa2GU55OhvW0
"""

# !pip install unsloth
# !pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git

pip install unsloth unsloth_zoo --no-cache-dir

from unsloth import FastLanguageModel
import torch
from transformers import TrainingArguments
import wandb
from datasets import load_dataset



from huggingface_hub import login
from google.colab import userdata

hf_token = userdata.get("HF_TOKEN")
login(hf_token)

#Loading the dataset

from itertools import islice
dataset_stream = load_dataset('Prarabdha/indian-legal-supervised-fine-tuning-data', split = "train", streaming = True)
law_dataset = list(islice(dataset_stream, 1000))

len(law_dataset)

law_dataset[12]

prompt_style = '''<s>[INST] <<SYS>>
You are a helpful assistant specialized in Indian law.
<</SYS>>

Context:
{}

Question:
{}
[/INST]
{}
'''

EOS_TOKEN = '</s>'

def preprocess_data(sample):
    context = sample["context"]
    question = sample["question"]
    answer = sample["response"]

    text = prompt_style.format(context, question, answer) + EOS_TOKEN

    return {"texts": text}

def formatting_prompts_func(examples):
    contexts  = examples["context"]
    questions = examples["question"]
    responses = examples["response"]
    texts = []

    # we use zip as whlist formatting in Trainer it recieve a batch which needs to be iterated and appeneded to.
    for context, question, response in zip(contexts, questions, responses):
        text = prompt_style.format(context, question, response) + EOS_TOKEN
        texts.append(text)

    return texts

preprocess_data(law_dataset[5])

from datasets import Dataset
law_dataset = Dataset.from_list(law_dataset)

finetune_dataset = law_dataset.map(preprocess_data)

finetune_dataset.column_names

finetune_dataset = finetune_dataset.remove_columns(["context", "question", "response"])

finetune_dataset.column_names

# Loading the model

model_name = 'meta-llama/Llama-2-7b-chat-hf'
dataset_name = 'Prarabdha/indian-legal-supervised-fine-tuning-data'

load_in_4bit = True
dtype = None
max_sequence_length = 2048

model, tokenizer = FastLanguageModel.from_pretrained(
    model_name = model_name,
    load_in_4bit = load_in_4bit,
    dtype = dtype,
    max_seq_length = max_sequence_length,
    use_gradient_checkpointing='unsloth',
    random_state = 3407
)

model_lora = FastLanguageModel.get_peft_model(
    model = model,
    r = 16,
    target_modules = ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],
    lora_alpha = 16,
    lora_dropout=0.0,
    bias='none',
    use_gradient_checkpointing='unsloth',
    random_state=3407

)

from trl import SFTTrainer

from unsloth import is_bfloat16_supported

trainer = SFTTrainer(
    model = model_lora,
    tokenizer = tokenizer,
    train_dataset = law_dataset,
    formatting_func = formatting_prompts_func,
    max_seq_length = max_sequence_length,
    dataset_num_proc = 1,
    packing = False,

    args = TrainingArguments(
        output_dir = "outputs",
        per_device_train_batch_size = 1,
        gradient_accumulation_steps = 4,
        learning_rate = 2e-4,
        num_train_epochs = 1,
        max_steps = 300,
        warmup_steps = 5,
        fp16 = not is_bfloat16_supported(),
        bf16=is_bfloat16_supported(),
        logging_steps = 10,
        weight_decay = 0.1,
        optim = "adamw_8bit",
        lr_scheduler_type = 'linear',
        seed = 3407
    ),


)

import wandb
wnb_token = userdata.get("WAND_TOKEN")
wandb.login(key=wnb_token)
run = wandb.init(
    project='Fine-tune-Llama-2-7b-chat-on-Law-Dataset',
    job_type="training",
    anonymous="allow"
)

trainer_stas = trainer.train()

wandb.finish()

question = 'What measures did the government take to prevent the inflow of construction materials to the site?'

context = ''''The next question is whether these activities were carried on by a D\ncongregation of Sadhus at the site and not by the State Govt. and despite\nGovernments efforts. Apart from a glib suggestion that any attempt to\nprevent the work would have created a violent situation endangering the\nsafety of the Ram Janam Bhumi-Babri Masjid structure itself, nothing is\nindicated as to what was sought to be done at all to prevent constructional\nmaterial coming in.
There is no mention in any of the affidavits of any of E\nthe officers as to what reasonable measures the Government took to\nprevent the inflow of constructional material such as large quantities of\ncement, mortar, sand, constructional equipment, water-tankers etc. that\nwere necessary for the work.
The report of the Expert Committee has\nindicated that constructional machinery was indispensable having regard to F\nthe nature and magnitude of the work carried out. While it is\nunderstandable that the prevention of the gathering of Sadhus might have\ncreated some resentment, it is un-understandable why large quantities of\nbuilding materials were allowed to be brought on the land unless it be-\nand that must be the reasonable presumption- that the Government itself\nwas not too anxious to prevent it. It is not merely positive acts of violation G\nbut also surreptitious and indirect aids to circumvention and violation of the\norders that are equally impermissible.
If reasonable steps are not taken to\nprevent the violation of the orders of the Court, Government cannot be\nheard to say that violation of the orders were at the instance of others. The\npresumption is that the Government intended not to take such preventive\nsteps. In the facts and circumstances of the case, we are unable to persuade H\nA\nB\nc\nD\nE\nF\nG\nH   SUPa,EME COURT REPORTS   SUPP.  S.C.R.\nourselves to the view that the Government was helpless and the situation\nthat had developed was in spite of all reasonable steps taken by the\nGovernment.
Indeed there is no indication that the Government bestirred\nitself to take any steps, reasonable or otherwise, to prevent large scale\nbuilding material getting into the site. The Chief Minister having given a\nsolemn assurance to the National Integration Council and permitted the\nterms of that assurance to be incorporated at his own undertaking tq this\nCourt and allowed an order to be passed in those terms cannot absolve\nhimself of the responsibility unless he placed before the Court sufficient'''

FastLanguageModel.for_inference(model_lora)
inputs = tokenizer(prompt_style.format(context, question , ""), return_tensors = "pt").to("cuda")

outputs = model_lora.generate(
    input_ids = inputs.input_ids,
    attention_mask = inputs.attention_mask,
    max_new_tokens = 3000,
    use_cache = True
)

response = tokenizer.batch_decode(outputs)
print(response)

parts = str(response).split("[/INST]")
response_only = parts[-1].strip()
print(response_only)

raw_dataset_response = 'The government did not take any reasonable measures to prevent the inflow of construction materials such as cement, mortar, sand, constructional equipment, and water tankers to the site.'

print(raw_dataset_response)

#before training response:

question = 'What measures did the government take to prevent the inflow of construction materials to the site?'

context = ''''The next question is whether these activities were carried on by a D\ncongregation of Sadhus at the site and not by the State Govt. and despite\nGovernments efforts. Apart from a glib suggestion that any attempt to\nprevent the work would have created a violent situation endangering the\nsafety of the Ram Janam Bhumi-Babri Masjid structure itself, nothing is\nindicated as to what was sought to be done at all to prevent constructional\nmaterial coming in.
There is no mention in any of the affidavits of any of E\nthe officers as to what reasonable measures the Government took to\nprevent the inflow of constructional material such as large quantities of\ncement, mortar, sand, constructional equipment, water-tankers etc. that\nwere necessary for the work.
The report of the Expert Committee has\nindicated that constructional machinery was indispensable having regard to F\nthe nature and magnitude of the work carried out. While it is\nunderstandable that the prevention of the gathering of Sadhus might have\ncreated some resentment, it is un-understandable why large quantities of\nbuilding materials were allowed to be brought on the land unless it be-\nand that must be the reasonable presumption- that the Government itself\nwas not too anxious to prevent it. It is not merely positive acts of violation G\nbut also surreptitious and indirect aids to circumvention and violation of the\norders that are equally impermissible.
If reasonable steps are not taken to\nprevent the violation of the orders of the Court, Government cannot be\nheard to say that violation of the orders were at the instance of others. The\npresumption is that the Government intended not to take such preventive\nsteps. In the facts and circumstances of the case, we are unable to persuade H\nA\nB\nc\nD\nE\nF\nG\nH   SUPa,EME COURT REPORTS   SUPP.  S.C.R.\nourselves to the view that the Government was helpless and the situation\nthat had developed was in spite of all reasonable steps taken by the\nGovernment.
Indeed there is no indication that the Government bestirred\nitself to take any steps, reasonable or otherwise, to prevent large scale\nbuilding material getting into the site. The Chief Minister having given a\nsolemn assurance to the National Integration Council and permitted the\nterms of that assurance to be incorporated at his own undertaking tq this\nCourt and allowed an order to be passed in those terms cannot absolve\nhimself of the responsibility unless he placed before the Court sufficient'''

FastLanguageModel.for_inference(model)
inputs = tokenizer(prompt_style.format(context, question , ""), return_tensors = "pt").to("cuda")

outputs = model.generate(
    input_ids = inputs.input_ids,
    attention_mask = inputs.attention_mask,
    max_new_tokens = 3000,
    use_cache = False
)

response = tokenizer.batch_decode(outputs)
print(response)

parts = str(response).split("[/INST]")
response_only = parts[-1].strip()
print(response_only)

